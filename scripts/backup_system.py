#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –±—ç–∫–∞–ø–æ–≤ –¥–ª—è Telegram Bot
- –°–æ–∑–¥–∞–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –±—ç–∫–∞–ø—ã –∫–æ–¥–∞ –∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç –±—ç–∫–∞–ø—ã —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
- –õ–æ–≥–∏—Ä—É–µ—Ç –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
"""

import os
import shutil
import subprocess
import datetime
import glob
import logging
from pathlib import Path
import zipfile
import asyncio
import motor.motor_asyncio
from bson import json_util
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/backup_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BackupSystem:
    def __init__(self):
        self.app_dir = Path("/app")
        self.backup_dir = Path("/app/backups")
        self.backup_dir.mkdir(exist_ok=True)
        
        # MongoDB connection
        self.mongo_url = os.environ.get('MONGO_URL', 'mongodb://127.0.0.1:27017')
        
        # Retention period (days)
        self.retention_days = 30
        
    def create_timestamp(self):
        """–°–æ–∑–¥–∞—Ç—å timestamp –¥–ª—è –∏–º–µ–Ω–∏ –±—ç–∫–∞–ø–∞"""
        return datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    
    def backup_code(self):
        """–°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –∫–æ–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            timestamp = self.create_timestamp()
            backup_name = f"code_backup_{timestamp}"
            backup_path = self.backup_dir / backup_name
            
            logger.info(f"Starting code backup: {backup_name}")
            
            # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –±—ç–∫–∞–ø–∞
            backup_path.mkdir(exist_ok=True)
            
            # –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ —Ñ–∞–π–ª—ã
            important_paths = [
                "backend",
                "frontend", 
                "scripts",
                "documentation",
                "README.md",
                "test_result.md"
            ]
            
            for path_name in important_paths:
                source_path = self.app_dir / path_name
                if source_path.exists():
                    dest_path = backup_path / path_name
                    
                    if source_path.is_dir():
                        shutil.copytree(source_path, dest_path, ignore=shutil.ignore_patterns(
                            '__pycache__', '*.pyc', 'node_modules', '*.log', 'yarn.lock'
                        ))
                    else:
                        shutil.copy2(source_path, dest_path)
                    
                    logger.info(f"Copied: {path_name}")
            
            # –°–æ–∑–¥–∞—Ç—å ZIP –∞—Ä—Ö–∏–≤
            zip_path = self.backup_dir / f"{backup_name}.zip"
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in backup_path.rglob('*'):
                    if file_path.is_file():
                        arcname = file_path.relative_to(backup_path)
                        zipf.write(file_path, arcname)
            
            # –£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            shutil.rmtree(backup_path)
            
            logger.info(f"Code backup completed: {zip_path}")
            return zip_path
            
        except Exception as e:
            logger.error(f"Code backup failed: {str(e)}")
            return None
    
    async def backup_database(self):
        """–°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö MongoDB"""
        try:
            timestamp = self.create_timestamp()
            backup_name = f"database_backup_{timestamp}.json"
            backup_path = self.backup_dir / backup_name
            
            logger.info(f"Starting database backup: {backup_name}")
            
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB
            client = motor.motor_asyncio.AsyncIOMotorClient(self.mongo_url)
            db = client.telegram_bot_db
            
            backup_data = {}
            
            # –ë—ç–∫–∞–ø –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π
            collections = await db.list_collection_names()
            
            for collection_name in collections:
                logger.info(f"Backing up collection: {collection_name}")
                collection = db[collection_name]
                
                # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                documents = []
                async for doc in collection.find():
                    documents.append(doc)
                
                backup_data[collection_name] = documents
                logger.info(f"Collection {collection_name}: {len(documents)} documents")
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON —Ñ–∞–π–ª
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, default=json_util.default, ensure_ascii=False, indent=2)
            
            client.close()
            
            # –°–æ–∑–¥–∞—Ç—å —Å–∂–∞—Ç—ã–π –∞—Ä—Ö–∏–≤
            zip_path = backup_path.with_suffix('.zip')
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                zipf.write(backup_path, backup_path.name)
            
            # –£–¥–∞–ª–∏—Ç—å JSON —Ñ–∞–π–ª
            backup_path.unlink()
            
            logger.info(f"Database backup completed: {zip_path}")
            return zip_path
            
        except Exception as e:
            logger.error(f"Database backup failed: {str(e)}")
            return None
    
    def cleanup_old_backups(self):
        """–£–¥–∞–ª–∏—Ç—å –±—ç–∫–∞–ø—ã —Å—Ç–∞—Ä—à–µ retention_days –¥–Ω–µ–π"""
        try:
            cutoff_date = datetime.datetime.now() - datetime.timedelta(days=self.retention_days)
            cutoff_timestamp = cutoff_date.strftime('%Y%m%d')
            
            logger.info(f"Cleaning up backups older than {self.retention_days} days (before {cutoff_timestamp})")
            
            # –ù–∞–π—Ç–∏ –≤—Å–µ —Ñ–∞–π–ª—ã –±—ç–∫–∞–ø–æ–≤
            backup_patterns = [
                "code_backup_*.zip",
                "database_backup_*.zip",
                "full_backup_*.zip"
            ]
            
            deleted_count = 0
            
            for pattern in backup_patterns:
                for backup_file in self.backup_dir.glob(pattern):
                    # –ò–∑–≤–ª–µ—á—å timestamp –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    filename = backup_file.stem
                    try:
                        # –ù–∞–π—Ç–∏ timestamp –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (YYYYMMDD_HHMMSS)
                        timestamp_part = filename.split('_')[-2]  # –ü–æ–ª—É—á–∏—Ç—å YYYYMMDD
                        
                        if timestamp_part < cutoff_timestamp:
                            backup_file.unlink()
                            logger.info(f"Deleted old backup: {backup_file.name}")
                            deleted_count += 1
                            
                    except (IndexError, ValueError):
                        logger.warning(f"Could not parse timestamp from {backup_file.name}")
            
            logger.info(f"Cleanup completed: {deleted_count} old backups deleted")
            
        except Exception as e:
            logger.error(f"Backup cleanup failed: {str(e)}")
    
    def get_backup_stats(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±—ç–∫–∞–ø–æ–≤"""
        try:
            backup_files = list(self.backup_dir.glob("*.zip"))
            total_size = sum(f.stat().st_size for f in backup_files)
            
            stats = {
                "total_backups": len(backup_files),
                "total_size_mb": round(total_size / (1024 * 1024), 2),
                "backup_directory": str(self.backup_dir),
                "retention_days": self.retention_days
            }
            
            logger.info(f"Backup stats: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"Failed to get backup stats: {str(e)}")
            return None
    
    async def create_full_backup(self):
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø (–∫–æ–¥ + –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö)"""
        try:
            timestamp = self.create_timestamp()
            logger.info(f"Starting full backup: {timestamp}")
            
            # –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –∫–æ–¥–∞
            code_backup = self.backup_code()
            
            # –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö  
            db_backup = await self.backup_database()
            
            if code_backup and db_backup:
                # –°–æ–∑–¥–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤
                full_backup_path = self.backup_dir / f"full_backup_{timestamp}.zip"
                
                with zipfile.ZipFile(full_backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # –î–æ–±–∞–≤–∏—Ç—å –±—ç–∫–∞–ø –∫–æ–¥–∞
                    zipf.write(code_backup, f"code_{code_backup.name}")
                    
                    # –î–æ–±–∞–≤–∏—Ç—å –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                    zipf.write(db_backup, f"database_{db_backup.name}")
                
                # –£–¥–∞–ª–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∞—Ä—Ö–∏–≤—ã
                code_backup.unlink()
                db_backup.unlink()
                
                logger.info(f"Full backup completed: {full_backup_path}")
                return full_backup_path
            else:
                logger.error("Full backup failed - one or both components failed")
                return None
                
        except Exception as e:
            logger.error(f"Full backup failed: {str(e)}")
            return None

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±—ç–∫–∞–ø–∞"""
    backup_system = BackupSystem()
    
    logger.info("=== BACKUP SYSTEM STARTED ===")
    
    # –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø
    backup_path = await backup_system.create_full_backup()
    
    if backup_path:
        logger.info(f"‚úÖ Backup successful: {backup_path}")
    else:
        logger.error("‚ùå Backup failed")
    
    # –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
    backup_system.cleanup_old_backups()
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = backup_system.get_backup_stats()
    if stats:
        logger.info(f"üìä Backup statistics: {stats}")
    
    logger.info("=== BACKUP SYSTEM COMPLETED ===")

if __name__ == "__main__":
    asyncio.run(main())